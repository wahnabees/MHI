\section{Future Work}
\label{sec:future}

The results obtained using Hu moments across SVM, KNN, and MLP suggest that the
main limitation lies in the expressiveness of the features rather than the
classifiers. Improving the quality of the descriptors is therefore the most
promising direction for increasing recognition accuracy. Several focused
extensions are outlined below.

\subsection{Richer Spatial Descriptors: HOG Features}

Hu moments capture only coarse global shape. Incorporating more expressive
handcrafted descriptors such as Histograms of Oriented Gradients (HOG) could
provide finer spatial detail and strengthen class separability. Since the
existing MHI/MEI pipeline already supports gradient-based representations, HOG
offers a natural next step for comparison and improvement.

\subsection{Deep Feature Extraction Using CNNs}

Convolutional neural networks learn high-level spatial representations directly
from data and have demonstrated strong performance in action-recognition
tasks~\cite{simonyan2014twostream}. Applying CNN-based feature extraction to
MHI/MEI templates—or directly to raw video frames—may yield richer and more
robust descriptors than handcrafted features, enabling the model to learn
discriminative motion cues automatically.

\subsection{Temporal Modeling Beyond Static Templates}

MHI and MEI compress motion into a single static image, discarding temporal
ordering. Future extensions could incorporate models that preserve sequence
structure, such as LSTMs, GRUs, or temporal CNNs~\cite{ji2013cnn}. These
approaches capture how motion evolves over time and may improve performance on
actions where temporal progression is critical.

Overall, richer handcrafted descriptors, learned deep features, and explicit
temporal modeling represent promising pathways for advancing the performance of
template-based human activity recognition systems.
