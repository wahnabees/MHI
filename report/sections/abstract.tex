\begin{abstract}
    This paper presents a human activity recognition system that leverages Motion
    History Images (MHI) and Motion Energy Images (MEI) in combination with
    classical machine learning classifiers, including Support Vector Machines
    (SVM), $k$-Nearest Neighbors (KNN), and Multi-Layer Perceptrons (MLP). Using Hu
    moment descriptors extracted from the motion templates, we first evaluate how
    each classifier performs under a compact, low-dimensional representation of
    global motion shape. We then extend this representation by introducing a set of
    auxiliary motion features that capture temporal variation, spatial motion
    distribution, and localized activity intensity.
    
    Through these refinements—together with calibrated motion thresholds and
    temporal decay parameters—the SVM classifier shows a substantial improvement in
    both validation and video-level accuracy, surpassing the performance of all
    baseline Hu-only models. The results demonstrate that simple engineered motion
    descriptors can meaningfully enhance the discriminative power of traditional
    temporal templates, while also motivating the exploration of richer feature
    representations, such as HOG or learned deep features, in future work.
\end{abstract}
